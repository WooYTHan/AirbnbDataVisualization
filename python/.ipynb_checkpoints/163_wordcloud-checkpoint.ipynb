{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "city = ['chi', 'nyc', 'sea', 'sf', 'wdc']\n",
    "for c in city:\n",
    "    # Read csv files\n",
    "    with open(\"../csv/\" + c + '_listing.csv') as csvfile:\n",
    "        words = ''\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            words = words + row['description']\n",
    "\n",
    "    # Word Cloud of the whole City\n",
    "    words = words.lower()\n",
    "    for p in string.punctuation:\n",
    "        words = words.replace(p,\"\")\n",
    "\n",
    "    text_word = words.split()\n",
    "    df = pd.DataFrame({'count': text_word})\n",
    "\n",
    "    stop = set(stopwords.words('english')) \n",
    "    stop.add('w')\n",
    "    stop.add('room')\n",
    "    stop = map(str, stop)\n",
    "\n",
    "    mostCover = pd.DataFrame()\n",
    "\n",
    "    mostCover = pd.DataFrame(df['count'].value_counts())\n",
    "    mostCover['word'] = mostCover.index\n",
    "    mostCover['neighbourhood'] = \"\"\n",
    "    mostCover = mostCover.loc[[w not in stop for w in mostCover['word']], :]\n",
    "    mostCover = mostCover.loc[[w.isalpha() for w in mostCover['word']], :]\n",
    "    mostCover = mostCover.loc[[len(w) >= 2 for w in mostCover['word']], :]\n",
    "    mostCover = mostCover.head(300)\n",
    "\n",
    "    with open(\"../csv/\" + c + '_listing.csv') as csvfile:\n",
    "        maindf = pd.DataFrame.from_csv(csvfile)\n",
    "\n",
    "    # Create file for neighbourhood\n",
    "    neighbourhoods = maindf['neighbourhood'].unique()\n",
    "    for n in neighbourhoods:\n",
    "        tempdf = maindf.loc[(maindf.neighbourhood == n), ['description']]\n",
    "        neww = str(tempdf.description)[3:]\n",
    "\n",
    "        words = neww.lower()\n",
    "        for p in string.punctuation:\n",
    "            words = words.replace(p,\"\")\n",
    "        words = words.replace('â€™',\"\")\n",
    "        text_word = words.split()\n",
    "        df = pd.DataFrame({'count': text_word})\n",
    "\n",
    "        stop = set(stopwords.words('english')) \n",
    "        stop.add('w')\n",
    "        stop.add('room')\n",
    "        stop = map(str, stop)\n",
    "\n",
    "        temp = pd.DataFrame()\n",
    "\n",
    "        temp = pd.DataFrame(df['count'].value_counts())\n",
    "        temp['word'] = temp.index\n",
    "        temp['neighbourhood'] = n\n",
    "        temp = temp.loc[[w not in stop for w in temp['word']], :]\n",
    "        temp = temp.loc[[w.isalpha() for w in temp['word']], :]\n",
    "        temp = temp.loc[[len(w) >= 2 for w in temp['word']], :]\n",
    "        \n",
    "        if (len(tempdf.index) >= 150) :\n",
    "            mostCover = mostCover.append(temp.head(300), ignore_index = True, verify_integrity  = True)\n",
    "        else:\n",
    "            mostCover = mostCover.append(temp.head(len(tempdf.index) * 2) , ignore_index = True, verify_integrity  = True)\n",
    "\n",
    "    mostCover.to_csv(\"../wordcloud/\" + c + \"_desc_wordcloud.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
